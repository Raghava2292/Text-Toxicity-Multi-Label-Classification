{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building - LSTM and BiLSTM\n",
    "\n",
    "Here, the LSTM and the Bidirectional LSTM Recurrent Neural Networks will be used for the training process. Both of them uses the RNN structure in which the training is done in a series of steps where the output of a step will be used as an input for the next step along with the respective input of that step. This helps in maintaining a relationship between the outputs at different steps. Normally the RNNs are used for time series forecasting. But this can also be used for the text analysis. The LSTM and BiLSTM are are certain variations of the regular RNN.\n",
    "\n",
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import codecs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>daww matches background colour seemingly stuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0      0             0        0       0       0              0   \n",
       "1      0             0        0       0       0              0   \n",
       "2      0             0        0       0       0              0   \n",
       "3      0             0        0       0       0              0   \n",
       "4      0             0        0       0       0              0   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  daww matches background colour seemingly stuck...  \n",
       "2  hey man really trying edit war guy constantly ...  \n",
       "3  make real suggestions improvement wondered sec...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('cleaned_text2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   toxic          159571 non-null  int64 \n",
      " 1   severe_toxic   159571 non-null  int64 \n",
      " 2   obscene        159571 non-null  int64 \n",
      " 3   threat         159571 non-null  int64 \n",
      " 4   insult         159571 non-null  int64 \n",
      " 5   identity_hate  159571 non-null  int64 \n",
      " 6   cleaned_text   159471 non-null  object\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>daww matches background colour seemingly stuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>second time asking view completely contradicts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ashamed horrible thing put talk page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm theres actual article prostitution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>looks like actually put speedy first version d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>really think understand came idea bad right aw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151122 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0           0             0        0       0       0              0   \n",
       "1           0             0        0       0       0              0   \n",
       "2           0             0        0       0       0              0   \n",
       "3           0             0        0       0       0              0   \n",
       "4           0             0        0       0       0              0   \n",
       "...       ...           ...      ...     ...     ...            ...   \n",
       "159566      0             0        0       0       0              0   \n",
       "159567      0             0        0       0       0              0   \n",
       "159568      0             0        0       0       0              0   \n",
       "159569      0             0        0       0       0              0   \n",
       "159570      0             0        0       0       0              0   \n",
       "\n",
       "                                             cleaned_text  \n",
       "0       explanation edits made username hardcore metal...  \n",
       "1       daww matches background colour seemingly stuck...  \n",
       "2       hey man really trying edit war guy constantly ...  \n",
       "3       make real suggestions improvement wondered sec...  \n",
       "4                           sir hero chance remember page  \n",
       "...                                                   ...  \n",
       "159566  second time asking view completely contradicts...  \n",
       "159567               ashamed horrible thing put talk page  \n",
       "159568  spitzer umm theres actual article prostitution...  \n",
       "159569  looks like actually put speedy first version d...  \n",
       "159570  really think understand came idea bad right aw...  \n",
       "\n",
       "[151122 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['obscene'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7926, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['obscene']==1) & (data['toxic'] == 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['insult']==1) & (data['toxic'] == 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['identity_hate']==1) & (data['toxic'] == 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hi back last warning stop undoing edits die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>think fagget get oife burn hell hate sorry can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>also sock puppet account suprise sincerely man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fuck smith please notified die want dance grave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>wouldnt first time bitch fuck ill find live so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "79        1             0        0       1       0              0   \n",
       "176       1             0        1       1       1              1   \n",
       "600       1             0        0       1       0              0   \n",
       "802       1             0        1       1       1              0   \n",
       "1017      1             1        1       1       1              1   \n",
       "\n",
       "                                           cleaned_text  \n",
       "79          hi back last warning stop undoing edits die  \n",
       "176   think fagget get oife burn hell hate sorry can...  \n",
       "600   also sock puppet account suprise sincerely man...  \n",
       "802     fuck smith please notified die want dance grave  \n",
       "1017  wouldnt first time bitch fuck ill find live so...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['threat']==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text'] = data['cleaned_text'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96090</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support thanks hard work checked every detail ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63180</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>redirect talk celebrity big brother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34659</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>want company name history presented wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks looks useful honest think time knowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31191</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>white racist white girl makes think talk anoth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "96090      0             0        0       0       0              0   \n",
       "63180      0             0        0       0       0              0   \n",
       "34659      0             0        0       0       0              0   \n",
       "63397      0             0        0       0       0              0   \n",
       "31191      1             0        0       1       1              1   \n",
       "\n",
       "                                            cleaned_text  \n",
       "96090  support thanks hard work checked every detail ...  \n",
       "63180                redirect talk celebrity big brother  \n",
       "34659      want company name history presented wikipedia  \n",
       "63397  thanks looks useful honest think time knowledg...  \n",
       "31191  white racist white girl makes think talk anoth...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "For LSTM and BiLSTM another tokenization and word vectorization is used which is different from the ones used for the regular models that were built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 400\n",
    "MAX_NB_WORDS = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data tensor: (127656, 400)\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer(lower=False, filters='',num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(train['cleaned_text'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(train['cleaned_text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test['cleaned_text'])\n",
    "\n",
    "train_data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of train data tensor:', train_data.shape)\n",
    "\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "nb_words = (np.max(train_data) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer_lstm.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(nb_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 400)]             0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 400, 128)          6400000   \n",
      "                                                                 \n",
      " lstm_layer (LSTM)           (None, 400, 60)           45360     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 60)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                3050      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 306       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,448,716\n",
      "Trainable params: 6,448,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "# size of the vector space\n",
    "embed_size = 128\n",
    "x = Embedding(nb_words, embed_size)(inp)\n",
    "output_dimention = 60\n",
    "x = LSTM(output_dimention, return_sequences=True,name='lstm_layer')(x)\n",
    "# reduce dimention\n",
    "x = GlobalMaxPool1D()(x)\n",
    "# disable 10% precent of the nodes\n",
    "x = Dropout(0.1)(x)\n",
    "# pass output through a RELU function\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "# another 10% dropout\n",
    "x = Dropout(0.1)(x)\n",
    "# pass the output through a sigmoid layer, since \n",
    "# we are looking for a binary (0,1) classification\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[labels].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3591/3591 [==============================] - 1046s 291ms/step - loss: 0.0774 - accuracy: 0.9431 - val_loss: 0.0516 - val_accuracy: 0.9947\n",
      "Epoch 2/2\n",
      "3591/3591 [==============================] - 1034s 288ms/step - loss: 0.0446 - accuracy: 0.9928 - val_loss: 0.0497 - val_accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a59eb9ba90>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,y, batch_size=32, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, hamming_loss, log_loss\n",
    "def evaluate_score(Y_test,predict): \n",
    "    accuracy = accuracy_score(Y_test,predict)\n",
    "    print(\"Accuracy : {}\".format(accuracy*100))\n",
    "    print(f'Hamming Loss : {hamming_loss(Y_test, predict)}')\n",
    "    try : \n",
    "        loss = log_loss(Y_test,predict)\n",
    "    except :\n",
    "        loss = log_loss(Y_test,predict.toarray())\n",
    "    print(\"Log_loss : {}\".format(loss))\n",
    "    return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998/998 [==============================] - 62s 62ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.13038845e-04, 2.74493942e-07, 3.21314837e-05, 2.97820202e-06,\n",
       "        1.21085184e-04, 9.38685389e-06],\n",
       "       [9.93320286e-01, 1.88148811e-01, 9.61634099e-01, 2.57386416e-02,\n",
       "        7.69616425e-01, 9.87762213e-02],\n",
       "       [2.44177748e-02, 7.25165155e-05, 1.63619174e-03, 5.83332439e-04,\n",
       "        3.94833507e-03, 6.91708352e-04],\n",
       "       [1.25453772e-03, 1.18742480e-06, 5.81385975e-05, 1.25671186e-05,\n",
       "        2.16187982e-04, 2.45843803e-05],\n",
       "       [7.10039914e-01, 2.90427054e-03, 1.55623555e-01, 5.39087411e-03,\n",
       "        2.83621013e-01, 1.80782434e-02],\n",
       "       [5.13999909e-03, 6.88245655e-06, 2.41900023e-04, 7.88985708e-05,\n",
       "        8.41708214e-04, 1.05906271e-04],\n",
       "       [2.73356144e-03, 1.18653611e-06, 9.57825687e-05, 1.57736704e-05,\n",
       "        3.62441147e-04, 3.21693769e-05],\n",
       "       [9.85717177e-01, 2.25447029e-01, 9.35743093e-01, 5.58339618e-02,\n",
       "        7.93467164e-01, 1.84385374e-01],\n",
       "       [5.77867553e-02, 2.03859763e-05, 1.90499832e-03, 1.95712026e-04,\n",
       "        5.56305982e-03, 4.63394914e-04],\n",
       "       [9.85652387e-01, 7.19855428e-02, 9.65115905e-01, 7.86492974e-03,\n",
       "        6.00767910e-01, 3.67261507e-02]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_data)\n",
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test[labels].values\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.13038845e-04, 2.74493942e-07, 3.21314837e-05, 2.97820202e-06,\n",
       "        1.21085184e-04, 9.38685389e-06],\n",
       "       [9.93320286e-01, 1.88148811e-01, 9.61634099e-01, 2.57386416e-02,\n",
       "        7.69616425e-01, 9.87762213e-02],\n",
       "       [2.44177748e-02, 7.25165155e-05, 1.63619174e-03, 5.83332439e-04,\n",
       "        3.94833507e-03, 6.91708352e-04],\n",
       "       ...,\n",
       "       [1.19458139e-02, 1.03232451e-05, 1.26814982e-03, 4.16561707e-05,\n",
       "        1.96341448e-03, 2.02212526e-04],\n",
       "       [6.16130070e-04, 2.26648822e-07, 2.09067566e-05, 2.60966021e-06,\n",
       "        8.46088515e-05, 6.25734401e-06],\n",
       "       [3.34688026e-04, 1.08087853e-07, 1.22838510e-05, 1.10674159e-06,\n",
       "        4.93516673e-05, 3.49544007e-06]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 92.01942660191132\n",
      "Hamming Loss : 0.01732727557574808\n",
      "Log_loss : 0.7293063023457708\n"
     ]
    }
   ],
   "source": [
    "lstm_acc, lstm_loss = evaluate_score(y_test, pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LSTM_toxic_prediction_model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 400)]             0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 400, 128)          6400000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 400, 120)         90720     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 120)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                6050      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 306       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,497,076\n",
      "Trainable params: 6,497,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "# size of the vector space\n",
    "embed_size = 128\n",
    "bi = Embedding(nb_words, embed_size)(inp)\n",
    "output_dimention = 60\n",
    "bi = Bidirectional(LSTM(output_dimention, return_sequences=True,name='lstm_layer'))(bi)\n",
    "# reduce dimention\n",
    "bi = GlobalMaxPool1D()(bi)\n",
    "# disable 10% precent of the nodes\n",
    "bi = Dropout(0.1)(bi)\n",
    "# pass output through a RELU function\n",
    "bi = Dense(50, activation=\"relu\")(bi)\n",
    "# another 10% dropout\n",
    "bi = Dropout(0.1)(bi)\n",
    "# pass the output through a sigmoid layer, since \n",
    "# we are looking for a binary (0,1) classification\n",
    "bi = Dense(6, activation=\"sigmoid\")(bi)\n",
    "\n",
    "model_bi = Model(inputs=inp, outputs=bi)\n",
    "\n",
    "model_bi.summary()\n",
    "model_bi.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3591/3591 [==============================] - 1750s 486ms/step - loss: 0.0654 - accuracy: 0.9399 - val_loss: 0.0509 - val_accuracy: 0.9947\n",
      "Epoch 2/2\n",
      "3591/3591 [==============================] - 1781s 496ms/step - loss: 0.0436 - accuracy: 0.9867 - val_loss: 0.0504 - val_accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5a3df3130>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bi.fit(train_data,y, batch_size=32, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998/998 [==============================] - 106s 105ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_bi = model_bi.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 91.82202725990913\n",
      "Hamming Loss : 0.017755496370567652\n",
      "Log_loss : 0.7425914205369538\n"
     ]
    }
   ],
   "source": [
    "bilstm_acc, bilstm_loss = evaluate_score(y_test, y_pred_bi.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bi.save('BiLSTM_toxic_prediction_model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We are storing our model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''##########[!] Functions to be used###############'''\n",
    "def remove_contractions(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def remove_punctuations(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def clean_sentences(sentence):\n",
    "    sentence = str(sentence)\n",
    "    sentence= re.sub(r\"http\\S+\", \"\", sentence)\n",
    "    sentence = BeautifulSoup(sentence, 'lxml').get_text()\n",
    "    sentence = remove_contractions(sentence)\n",
    "    sentence = remove_punctuations(sentence)\n",
    "    sentence = re.sub(\"\\S*\\d\\S*\", \"\", sentence).strip()\n",
    "    sentence = re.sub('[^A-Za-z]+', ' ', sentence)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\n",
    "    sentence = ' '.join(e.lower() for e in sentence.split() if e.lower() not in  stopwords.words('english'))\n",
    "    return sentence.strip()\n",
    "\n",
    "def tokenize(sentence):\n",
    "    MAX_SEQUENCE_LENGTH = 400\n",
    "    #MAX_NB_WORDS = 50000\n",
    "    with open('tokenizer_lstm.pickle', 'rb') as handle:\n",
    "                    tokenizer = pickle.load(handle)\n",
    "    test_sequences = tokenizer.texts_to_sequences([sentence])\n",
    "    test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    return test_data\n",
    "\n",
    "def model_predict(model, test_data):\n",
    "    from keras.models import load_model\n",
    "    if model == 'lstm':\n",
    "        model=load_model('LSTM_toxic_prediction_model2.h5')\n",
    "    elif model == 'bilstm':\n",
    "        model = load_model('BiLSTM_toxic_prediction_model.h5')\n",
    "    prediction=model.predict(test_data)    \n",
    "    return prediction\n",
    "\n",
    "def get_prediction(model, sentence):\n",
    "    clear_text=clean_sentences(sentence)\n",
    "    test_data=tokenize(clear_text)\n",
    "    predicted_array=model_predict(model, test_data)\n",
    "    #'identity_hate', 'insult', 'obscene', 'severe_toxic', 'threat', 'toxic'\n",
    "    predicted_values={'Toxic':round(predicted_array[0][0]),'Severe Toxic':round(predicted_array[0][1]), 'Obscene':round(predicted_array[0][2]), 'Threat':round(predicted_array[0][3]), 'Insult':round(predicted_array[0][4]), 'Hatred':round(predicted_array[0][5])}\n",
    "    #print(clear_text)\n",
    "    #print(test_data)\n",
    "    print(predicted_array[0])\n",
    "    result_list=[]\n",
    "    for key in predicted_values:\n",
    "        #print(key)\n",
    "        #print(predicted_values[key])\n",
    "        if(predicted_values[key]==1.0):\n",
    "            result_list.append(key)\n",
    "    result = (',').join(result_list)\n",
    "    if result == 'Toxic,Severe Toxic,Obscene,Insult':\n",
    "        result_cat = 'Intense Malicious Disparagement'\n",
    "        toxic_per = 90\n",
    "    elif result == 'Toxic,Obscene,Insult,Hatred':\n",
    "        result_cat = 'Venomous Reprehension'\n",
    "        toxic_per = 80\n",
    "    elif result == 'Toxic,Obscene,Insult':\n",
    "        result_cat = 'Malicious Indecency'\n",
    "        toxic_per = 70\n",
    "    elif result == 'Toxic,Obscene':\n",
    "        result_cat = 'Noxious'\n",
    "        toxic_per = 60\n",
    "    elif result == 'Toxic,Threat':\n",
    "        result_cat = 'Menacing'\n",
    "        toxic_per = 50\n",
    "    elif result == 'Toxic,Insult':\n",
    "        result_cat = 'Offensive'\n",
    "        toxic_per = 50\n",
    "    elif result == 'Toxic,Obscene,Threat,Insult,Hatred':\n",
    "        result_cat = 'Malevolent Vulgarity'\n",
    "        toxic_per = 95\n",
    "    elif result == 'Toxic,Severe Toxic,Obscene':\n",
    "        result_cat = 'Intense Contamination'\n",
    "        toxic_per = 80\n",
    "    elif result == 'Toxic,Obscene,Threat,Insult':\n",
    "        result_cat = 'Dangerous Provocation'\n",
    "        toxic_per = 85\n",
    "    elif result == 'Toxic,Severe Toxic,Obscene,Insult,Hatred':\n",
    "        result_cat = 'Excessive Malevolence'\n",
    "        toxic_per = 90\n",
    "    elif result == 'Toxic,Severe Toxic,Obscene,Threat,Insult,Hatred':\n",
    "        result_cat = 'Overwhelming Hostility'\n",
    "        toxic_per = 95\n",
    "    elif result == 'Toxic,Insult,Hatred':\n",
    "        result_cat = 'Hostile Disdain'\n",
    "        toxic_per = 70\n",
    "    elif result == 'Toxic,Hatred':\n",
    "        result_cat = 'Virulent Hostility'\n",
    "        toxic_per = 60\n",
    "    elif result == 'Obscene,Insult':\n",
    "        result_cat = 'Vulgar Reproach'\n",
    "        toxic_per = 70\n",
    "    elif result == 'Toxic,Severe Toxic,Obscene,Hatred':\n",
    "        result_cat = 'Excessive Hostility'\n",
    "        toxic_per = 85\n",
    "    elif result == 'Toxic,Severe Toxic,Obscene,Threat,Insult':\n",
    "        result_cat = 'Overwhelming Menace'\n",
    "        toxic_per = 90\n",
    "    elif result == 'Toxic,Obscene,Hatred':\n",
    "        result_cat = 'Harmful Repugnance'\n",
    "        toxic_per = 75\n",
    "    elif result == 'Obscene,Insult,Hatred':\n",
    "        result_cat = 'Indecent Contempt'\n",
    "        toxic_per = 80\n",
    "    elif result == 'Toxic,Severe Toxic':\n",
    "        result_cat = 'Intense Toxicity'\n",
    "        toxic_per = 60\n",
    "    elif result == 'Toxic,Severe Toxic,Insult':\n",
    "        result_cat = 'Severe Disdain'\n",
    "        toxic_per = 70\n",
    "    elif result == 'Toxic,Severe Toxic,Hatred':\n",
    "        result_cat = 'Intense Malevolence'\n",
    "        toxic_per = 80\n",
    "    elif result == 'Obscene,Threat':\n",
    "        result_cat = 'Offensive Threat'\n",
    "        toxic_per = 50\n",
    "    elif result == 'Toxic,Threat,Insult':\n",
    "        result_cat = 'Hazardous Assault'\n",
    "        toxic_per = 60\n",
    "    elif result == 'Insult,Hatred':\n",
    "        result_cat = 'Offensive Animosity'\n",
    "        toxic_per = 60\n",
    "    elif result == 'Toxic,Severe Toxic,Obscene,Threat':\n",
    "        result_cat = 'Overwhelming Peril'\n",
    "        toxic_per = 90\n",
    "    elif result == 'Toxic,Severe Toxic,Insult,Hatred':\n",
    "        result_cat = 'Intense Hostility'\n",
    "        toxic_per = 90\n",
    "    elif result == 'Toxic,Obscene,Threat':\n",
    "        result_cat = 'Hazardous Provocation'\n",
    "        toxic_per = 80\n",
    "    elif result == 'Toxic,Severe Toxic,Threat':\n",
    "        result_cat = 'Severe Menace'\n",
    "        toxic_per = 85\n",
    "    elif result == 'Threat,Insult':\n",
    "        result_cat = 'Threatening Disdain'\n",
    "        toxic_per = 50\n",
    "    elif result == 'Toxic,Threat,Insult,Hatred':\n",
    "        result_cat = 'Perilous Animosity'\n",
    "        toxic_per = 75\n",
    "    elif result == 'Toxic,Threat,Hatred':\n",
    "        result_cat = 'Dangerous Hostility'\n",
    "        toxic_per = 80\n",
    "    elif result == 'Obscene,Threat,Insult':\n",
    "        result_cat = 'Indecent Threat'\n",
    "        toxic_per = 70\n",
    "    elif result == 'Toxic,Severe Toxic,Threat,Insult':\n",
    "        result_cat = 'Intense Disparagement'\n",
    "        toxic_per = 85\n",
    "    elif result == 'Toxic,Severe Toxic,Threat,Hatred':\n",
    "        result_cat = 'Overwhelming Malevolence'\n",
    "        toxic_per = 90\n",
    "    elif result == 'Obscene,Hatred':\n",
    "        result_cat = 'Indecent Animosity'\n",
    "        toxic_per = 60\n",
    "    elif result == 'General':\n",
    "        result_cat = 'Harmless or Positive Commentary'\n",
    "        toxic_per = 0\n",
    "    elif result == 'Toxic':\n",
    "        result_cat = 'Toxic'\n",
    "        toxic_per = 40\n",
    "    elif result == 'Severe Toxic':\n",
    "        result_cat = 'Severe Toxic'\n",
    "        toxic_per = 50\n",
    "    elif result == 'Obscene':\n",
    "        result_cat = 'Obscene'\n",
    "        toxic_per = 50\n",
    "    elif result == 'Threat':\n",
    "        result_cat = 'Threat'\n",
    "        toxic_per = 50\n",
    "    elif result == 'Insult':\n",
    "        result_cat = 'Insult'\n",
    "        toxic_per = 50\n",
    "    elif result == 'Hatred':\n",
    "        result_cat = 'Hatred'\n",
    "        toxic_per = 60\n",
    "#     print(result)\n",
    "#     print(result_cat)\n",
    "#     print(toxic_per)\n",
    "    return result, result_cat, toxic_per\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toxic,Insult'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(['Toxic', 'Insult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 550ms/step\n",
      "[0.99742466 0.28200847 0.9733534  0.03681181 0.8689683  0.15827034]\n",
      "Toxic Obscene Insult \n"
     ]
    }
   ],
   "source": [
    "get_prediction('lstm', \"COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 997 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000250828F3880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 998 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000250851E53F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 549ms/step\n",
      "Hate Obscene Severe_Toxic \n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"BAstard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 612ms/step\n",
      "[0.99942267 0.51024634 0.9938762  0.04907466 0.93890274 0.25359315]\n",
      "Toxic Severe_Toxic Obscene Insult \n"
     ]
    }
   ],
   "source": [
    "get_prediction('lstm', 'Fuck OFF man , you peace of cunt. Mother fucker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "Both the LSTM and the BiLSTM models are trained here, and both of them gave very similar results. And the predictions are very accurate. So, these models can be finalized for the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
